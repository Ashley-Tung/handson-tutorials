# How to setup tutorial servers on MMCloud

## Login to the Opcenter

You would need to log in before submitting jobs to launch the Jupyter instances.
```
float login -u <username> -p <password> -a <opcenter_IP>
```

## Start a server using Float CLI

Assuming that 

- The gateway has been set up in the Opcenter.
- The security group for port 8888 is created in the AWS console.

The below is the command to submit the jupyter interactive job as the course, the end user will need to modify the `securityGroup` or `gateway` as his/she own environment.
```
yes|float submit -i docker.io/yiweizh/rockefeller-jupyter -n firstname_lastname --instType r5.large --publish 8888:8888 --vmPolicy "[onDemand=true]" --migratePolicy "[disable=true]" --securityGroup sg-02867677e76635b25 --withRoot=true --imageVolSize 30 --gateway g-9xahbrb5rkbs0ic8yzylk | grep 'id:' | awk -F'id: ' '{print $2}' | awk '{print $1}'
```
CLI Options Breakdown:
- `-i` Container image URL
- `-n` Job Name
- `--instType` The instance type you want to host the Jupyter server on
- `--publish` Port mapping between container and host
- `--vmPolicy [onDemand=true]` Specify the instance to be on-demand, so it won't have spot reclaims from AWS
- `--migratePolicy [disable=true]` Specify the migration policy to be disabled
- `--securityGroup` Specify the AWS security group to allow inbound access to port 8888
- `--imageVolSize` Specify the EBS volume size that backs up the file system for the container
- `--gateway` (Optional) Specify the gateway you want the job to be attached to
- The contexts after the pipe `|` will extract and print job ID to the terminal screen which is relevant to keep for suspending and restarting purpose

## Retrieve Login Token for the server
### CLI Way
Remember to substitite your job ID.

The first step is to get the IP address and the port.
```
IP_ADDRESS=$(float show -j "$jobid" | grep -A 1 portMappings | tail -n 1 | awk '{print $4}')
```

The second step is to retrieve the login url from the log and strip out the token.
```
url=$(float log -j "$jobid" cat stderr.autosave | grep token= | head -n 1)
token=$(echo "$url" | sed -E 's|.*http://[^/]+/(lab\?token=[a-zA-Z0-9]+).*|\1|')
```

The actual url could be constructed as follow:
```
new_url="http://$IP_ADDRESS/$token"
```
### Manual Way  (for reference; don't do this)
After the job is in `Execution` stage on MMC, please retrieve the Jupyter login token in stderr.autosave.
Inside your job, go to Attachments -> stderr.autosave, and search for:
```
[I 2024-04-09 21:56:49.090 ServerApp] Jupyter Server 2.13.0 is running at:
[I 2024-04-09 21:56:49.090 ServerApp] http://9486a94be75a:8888/lab?token=e466d716b939274a422d23a4b0aac9a68d4b408f6c9da644
[I 2024-04-09 21:56:49.090 ServerApp]     http://127.0.0.1:8888/lab?token=e466d716b939274a422d23a4b0aac9a68d4b408f6c9da644
```
where you could substitute `127.0.0.1` with the IP of the host instance, and paste the link inside a web browser.

## Suspend, resume and cancel

```
float suspend -j <job_id>
float resume -j <job_id>
float cancel -j <job_id>
```

## For teaching assistants

### Initial setup

- Follow instruction above aiming at successfully setting up one server, and able to login to it, to suspend and to resume
- Write a script to
    - collect all students names into job names like `<firstname>_<lastname>`
    - create the `float` command per student
    - collect all job ID generated by the `float` command
    - collect all the URL generated from the Jupyter server
- For the jupyter server list of URL and student names, generate a file [like this](https://github.com/statgenetics/statgen-courses/blob/master/.github/workflows/rockefeller_2024.csv) through a pull request. It can be any name but should have `csv` format and extension. 
- A couple of minutes after the PR is accepted, test if for a student listed in the CSV file, the corresponding server is avaiable as `https://statgenetics.github.io/statgen-courses/<firstname_lastname>`

### Setting up servers
- To set up servers, you will need to use a script [like this](https://github.com/cumc/handson-tutorials/blob/main/setup/submit_jupyters.py) to submit jobs to cloud at the same time.
- The procedure has two steps:
    - submit: this is to submit jobs and get job ID generated by `float` command
    ```
    python submit_jupyters.py submit <input.csv> <output_jobid.csv> --bucket_access_key <bucket_access_key> --bucket_secret_key <bucket_secret_key>
    ``` 
    This step will generate a `csv` file that have two columns, Name and Job ID.

    - get_url: this step will collect all the URL generated
    ```
    python submit_jobs.py get_url <output_jobid.csv> <output_url.csv>
    ```
- A list of student names, URL, and job ID will be generated, [for example.](https://github.com/statgenetics/statgen-courses/blob/master/.github/workflows/shenzhen_2024.csv).
- After PR the list, the corresponding server is avaiable as `https://statgenetics.github.io/statgen-courses/<firstname_lastname>`.

### Managing servers
To suspend, resume, or cancel large amount of jupyters, this [job manager script](https://github.com/cumc/handson-tutorials/blob/main/setup/manage_jobs.py) can be used. 
```
manage_jobs.py <suspend/resume/cancel> <output_url.csv>
```
`output_url.csv` is the output when setting up servers. 


### Maintenance

For Maintenance,
- After everything is setup and tested, we should keep all the instances suspended
- Right before lab session, we resume all instances
- Right after the lab session ends, we suspend again
- If anyone has an issue with their server for whatever reason, we will need to start a new one for him/her (submit job and add a line to the CSV file), and cancel the old one that no longer works.
